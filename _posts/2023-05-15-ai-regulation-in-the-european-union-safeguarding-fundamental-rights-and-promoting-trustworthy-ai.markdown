---
layout: post
title: AI Regulation in the European Unionâ€”Safeguarding Fundamental Rights and Promoting Trustworthy AI
tags: [ai, blog, europeanunion, eu]
image: '/images/posts/5.jpg'
published: true
---
Artificial intelligence (AI) technologies have emerged as a transformative force with the potential to revolutionize various sectors, including environment and health, the public sector, finance, mobility, home affairs, and agriculture. AI offers numerous benefits, such as improved prediction, optimised operations, resource allocation, and personalised services. However, the rise of AI systems also raises concerns about their implications for fundamental rights protected under the EU Charter of Fundamental Rights and the safety risks they pose to users when embedded in products and services.

Recognising the importance of addressing these challenges, the European Union (EU) has taken steps to develop a comprehensive regulatory framework for AI. The EU aims to adopt a "human-centric" approach that ensures Europeans can benefit from AI technologies while upholding EU values and principles. While the EU does not yet have a specific legal framework for AI, it has outlined its vision and intentions through various policy documents.

In 2019, the European Commission published non-binding Ethics Guidelines for Trustworthy AI and Policy and investment recommendations as a soft-law approach to AI regulation. However, in 2021, the Commission shifted toward a legislative approach with the Communication on Fostering a European approach to Artificial Intelligence. This shift highlights the need for a new regulatory framework to promote AI uptake and address associated risks.

The European Parliament has also played a crucial role in shaping the AI debate at the EU level. In 2017, the Parliament called for the assessment of AI's impact and the drafting of an EU framework for AI. Subsequently, it adopted several resolutions in 2020 and 2021, urging EU action and the adoption of legislation on AI in various fields, including ethics, liability, and civil and military uses.

The Council of the EU, representing the member states, has repeatedly called for the adoption of common AI rules. In 2020, the Council called on the Commission to propose concrete measures, considering existing legislation and adopting a risk-based and proportionate regulatory approach. The Council also emphasised the importance of identifying, predicting, and responding to the potential impacts of digital technologies, including AI, on fundamental rights.

To inform the development of AI regulation, the European Commission conducted a public consultation in 2020 and published an Impact Assessment of the proposed regulation. The assessment identified six main problems related to AI systems: increased risks to safety and security, violations of fundamental rights and Union values, inadequate authorities' powers and resources, legal uncertainty, mistrust in AI, and fragmented measures hindering the cross-border AI single market.

In response to these challenges, the Commission introduced a proposal for an AI act in April 2021. The act aims to ensure the proper functioning of the single market and the development and use of trustworthy AI systems in the EU. It establishes a harmonized legal framework for the development, market placement, and use of AI products and services. The act focuses on specific AI utilization and associated risks, categorizing AI systems into different levels of risk.

Under the proposed AI act, harmful AI practices that pose an unacceptable risk to safety, livelihoods, and rights are explicitly prohibited. These include the use of manipulative subliminal techniques, exploitation of vulnerable groups, social scoring by public authorities, and real-time remote biometric identification systems in publicly accessible spaces for law enforcement purposes.

Additionally, the AI act regulates high-risk AI systems, which may have an adverse impact on safety or fundamental rights. These systems are divided into two categories: those used as safety components or falling under existing Union health and safety legislation, and those deployed in specific areas such as biometric identification, critical infrastructure, education, employment, law enforcement, and administration of justice.

The regulation introduces requirements for conformity assessment, risk management, testing, transparency, human oversight, and cybersecurity for high-risk AI systems. Providers of high-risk AI systems must register them in an EU-wide database, conduct conformity assessments, and comply with the prescribed obligations. The act also includes provisions for AI systems with limited risk, which are subject to fewer transparency obligations, and AI systems with low or minimal risk, which have no additional legal obligations.

To ensure effective implementation, the proposed AI act establishes a European Artificial Intelligence Board at the EU level and designates competent national authorities at the member state level. National market surveillance authorities would assess compliance and have the power to take corrective measures if AI systems do not meet the requirements. Administrative fines can be imposed for non-compliance.

The proposed AI act has received both support and criticism from various stakeholders. Industry associations emphasize the need to avoid over-regulation and reduce compliance costs, particularly for small and medium-sized enterprises. Civil rights organizations call for stronger protections, including bans on certain AI practices and individual enforcement rights. Consumer organizations stress the importance of consumer protection and effective remedies.

Experts have raised concerns about the definition of AI systems, the risk-based approach, enforcement mechanisms, and coordination between authorities. There are calls for clearer definitions, better allocation of responsibility, enhanced enforcement structures, and the inclusion of individual enforcement rights. The need for democratic oversight and impact assessments on individuals and society is also emphasized.

The legislative process for the proposed AI act is underway, with the European Parliament and the Council of the EU reviewing and discussing the draft. Stakeholders' feedback and input are being considered to refine the act and address its potential shortcomings.

In conclusion, the EU recognises the potential benefits of AI while acknowledging the risks it poses to fundamental rights and user safety. The proposed AI act represents a significant step toward establishing a harmonised regulatory framework that safeguards fundamental rights, ensures safety, and promotes trustworthy AI systems. As the EU continues its efforts to shape AI regulation, it must strike a balance between innovation and protection to foster public trust and realise the full potential of AI technologies in a responsible and ethical manner.

### Key takeaway points:

1. AI technologies offer economic and societal benefits across various sectors, but they also raise concerns about fundamental rights and user safety.
2. The EU is committed to developing a "human-centric" approach to AI regulation, aligning with EU values and principles.
3. The EU initially adopted a soft-law approach with non-binding guidelines but later shifted toward a legislative approach to regulate AI.
4. The European Parliament and the Council of the EU have called for AI regulation and have issued resolutions urging EU action.
5. The European Commission conducted a public consultation and published an Impact Assessment to inform the development of AI regulation.
6. The proposed AI act aims to create a harmonised legal framework for the development, market placement, and use of trustworthy AI systems.
7. The act categorises AI systems into different risk levels, with specific regulations for harmful AI practices and high-risk AI systems.
8. High-risk AI systems require conformity assessments, compliance with various obligations, and registration in an EU-wide database.
9. The proposed AI act establishes a European Artificial Intelligence Board and designates competent national authorities for implementation and enforcement.
10. Stakeholders have provided feedback and recommendations, highlighting the need for clearer definitions, better enforcement mechanisms, and individual enforcement rights, among other concerns.